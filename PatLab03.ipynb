{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PatLab03.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMf6b87WTv9o57sLGCCzDmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abirahsan007/PatternLab/blob/main/PatLab03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruPo4YQg9w4p"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)\r\n",
        "%cd /content/gdrive/My Drive/pattern lab files/Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Y2dsfI-bWJ"
      },
      "source": [
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\r\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from sklearn.ensemble import AdaBoostClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbzwdf_2-mu2"
      },
      "source": [
        "Xtrain = np.load(f'./final datas/Xtrain.npy')\r\n",
        "Ytrain = np.load(f'./final datas/Ytrain.npy')\r\n",
        "Xtest = np.load(f'./final datas/Xtest.npy')\r\n",
        "Ytest = np.load(f'./final datas/Ytest.npy')\r\n",
        "\r\n",
        "with open('index_dict.pickle', 'rb') as handle:\r\n",
        "    index_dict = pickle.load(handle)\r\n",
        "index_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcP8GSFN-6dd"
      },
      "source": [
        "random.seed(13)\r\n",
        "\r\n",
        "features = {1 : '(CKSNAP1)', 2 : '(CKSNAP3)', 3 : '(CKSNAP5)', 4 : '(CKSNAP7)', 5 : '(CKSNAP9)', 6 : '(DAC7)', 7 : '(EIIP)', 8 : '(ENAC10)', 9 : '(ENAC5)', 10 : '(NCP)', 11 : '(PseEIIP)', 12 : '(TAC7)', 13 : '(binary)', 14 : '(kmer1)', 15 : '(kmer2)', 16 : '(kmer3)', 17 : '(kmer4)', 18 : '(kmer5)'}\r\n",
        "\r\n",
        "subgrp1 = [features[random.randint(1,18)] for i in range(5)]\r\n",
        "subgrp2 = [features[random.randint(1,18)] for i in range(5)]\r\n",
        "subgrp3 = [features[random.randint(1,18)] for i in range(5)]\r\n",
        "subgrp4 = [features[random.randint(1,18)] for i in range(5)]\r\n",
        "subgrp5 = [features[random.randint(1,18)] for i in range(5)]\r\n",
        "\r\n",
        "\r\n",
        "X1 = np.concatenate([Xtrain[ : ,  index_dict[x][0] : index_dict[x][1]+1] for x in subgrp1], axis = 1)\r\n",
        "X2 = np.concatenate([Xtrain[ : ,  index_dict[x][0] : index_dict[x][1]+1] for x in subgrp2], axis = 1)\r\n",
        "X3 = np.concatenate([Xtrain[ : ,  index_dict[x][0] : index_dict[x][1]+1] for x in subgrp3], axis = 1)\r\n",
        "X4 = np.concatenate([Xtrain[ : ,  index_dict[x][0] : index_dict[x][1]+1] for x in subgrp4], axis = 1)\r\n",
        "X5 = np.concatenate([Xtrain[ : ,  index_dict[x][0] : index_dict[x][1]+1] for x in subgrp5], axis = 1)\r\n",
        "\r\n",
        "Xs = [X1, X2, X3, X4, X5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fJdegSJDZ1W"
      },
      "source": [
        "subgroups = [subgrp1, subgrp2, subgrp3, subgrp4, subgrp5]\r\n",
        "for group in subgroups:\r\n",
        "  print(group)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBPIar4Djfm"
      },
      "source": [
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from numpy import mean\r\n",
        "\r\n",
        "kf = KFold(n_splits=5, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEVpotNMD8IQ"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvbmpmaCEFCf"
      },
      "source": [
        "lg = LogisticRegression(max_iter=500)\r\n",
        "\r\n",
        "for i,X in enumerate(Xs):\r\n",
        "  train_acc = []\r\n",
        "  test_acc = []\r\n",
        "  train_sensitivity = []\r\n",
        "  test_sensitivity = []\r\n",
        "  train_specificity = []\r\n",
        "  test_specificity = []\r\n",
        "  train_mcc = []\r\n",
        "  test_mcc = []\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index]\r\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\r\n",
        "    lg.fit(X_train, y_train)\r\n",
        "    y_pred = lg.predict(X_train)\r\n",
        "    train_acc.append(accuracy_score(y_train, y_pred))\r\n",
        "    cf = confusion_matrix(y_train, y_pred)\r\n",
        "    train_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    train_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    train_mcc.append(matthews_corrcoef(y_train, y_pred))\r\n",
        "\r\n",
        "    lg.fit(X_train, y_train)\r\n",
        "    y_pred = lg.predict(X_test)\r\n",
        "    test_acc.append(accuracy_score(y_test, y_pred))\r\n",
        "    cf = confusion_matrix(y_test, y_pred)\r\n",
        "    test_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    test_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    test_mcc.append(matthews_corrcoef(y_test, y_pred))\r\n",
        "  print(f'subgroup{i+1} accuracy in logistic regression \\n train -> {mean(train_acc)}  test -> {mean(test_acc)}')\r\n",
        "  print(f'subgroup{i+1} sensitivity in logistic regression \\n train -> {mean(train_sensitivity)}  test -> {mean(test_sensitivity)}')\r\n",
        "  print(f'subgroup{i+1} specificity in logistic regression \\n train -> {mean(train_specificity)}  test -> {mean(test_specificity)}')\r\n",
        "  print(f'subgroup{i+1} mcc in logistic regression \\n train -> {mean(train_mcc)}  test -> {mean(test_mcc)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWwlkBlTJEh5"
      },
      "source": [
        "XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZchzNvCI8ZY"
      },
      "source": [
        "xgbst = XGBClassifier()\r\n",
        "\r\n",
        "for i,X in enumerate(Xs):\r\n",
        "  train_acc = []\r\n",
        "  test_acc = []\r\n",
        "  train_sensitivity = []\r\n",
        "  test_sensitivity = []\r\n",
        "  train_specificity = []\r\n",
        "  test_specificity = []\r\n",
        "  train_mcc = []\r\n",
        "  test_mcc = []\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index]\r\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\r\n",
        "    xgbst.fit(X_train, y_train)\r\n",
        "    y_pred = xgbst.predict(X_train)\r\n",
        "    train_acc.append(accuracy_score(y_train, y_pred))\r\n",
        "    cf = confusion_matrix(y_train, y_pred)\r\n",
        "    train_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    train_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    train_mcc.append(matthews_corrcoef(y_train, y_pred))\r\n",
        "\r\n",
        "    xgbst.fit(X_train, y_train)\r\n",
        "    y_pred = xgbst.predict(X_test)\r\n",
        "    test_acc.append(accuracy_score(y_test, y_pred))\r\n",
        "    cf = confusion_matrix(y_test, y_pred)\r\n",
        "    test_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    test_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    test_mcc.append(matthews_corrcoef(y_test, y_pred))\r\n",
        "  print(f'subgroup{i+1} accuracy in XG boost \\n train -> {mean(train_acc)}  test -> {mean(test_acc)}')\r\n",
        "  print(f'subgroup{i+1} sensitivity in XG boost \\n train -> {mean(train_sensitivity)}  test -> {mean(test_sensitivity)}')\r\n",
        "  print(f'subgroup{i+1} specificity in XG boost \\n train -> {mean(train_specificity)}  test -> {mean(test_specificity)}')\r\n",
        "  print(f'subgroup{i+1} mcc in XG boost \\n train -> {mean(train_mcc)}  test -> {mean(test_mcc)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvy1AQSHJwbn"
      },
      "source": [
        "Ada Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx0tOmtpJ5BM"
      },
      "source": [
        "ab = AdaBoostClassifier()\r\n",
        "\r\n",
        "for i,X in enumerate(Xs):\r\n",
        "  train_acc = []\r\n",
        "  test_acc = []\r\n",
        "  train_sensitivity = []\r\n",
        "  test_sensitivity = []\r\n",
        "  train_specificity = []\r\n",
        "  test_specificity = []\r\n",
        "  train_mcc = []\r\n",
        "  test_mcc = []\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index]\r\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\r\n",
        "    ab.fit(X_train, y_train)\r\n",
        "    y_pred = ab.predict(X_train)\r\n",
        "    train_acc.append(accuracy_score(y_train, y_pred))\r\n",
        "    cf = confusion_matrix(y_train, y_pred)\r\n",
        "    train_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    train_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    train_mcc.append(matthews_corrcoef(y_train, y_pred))\r\n",
        "\r\n",
        "    ab.fit(X_train, y_train)\r\n",
        "    y_pred = ab.predict(X_test)\r\n",
        "    test_acc.append(accuracy_score(y_test, y_pred))\r\n",
        "    cf = confusion_matrix(y_test, y_pred)\r\n",
        "    test_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    test_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    test_mcc.append(matthews_corrcoef(y_test, y_pred))\r\n",
        "  print(f'subgroup{i+1} accuracy in Ada boost \\n train -> {mean(train_acc)}  test -> {mean(test_acc)}')\r\n",
        "  print(f'subgroup{i+1} sensitivity in Ada boost \\n train -> {mean(train_sensitivity)}  test -> {mean(test_sensitivity)}')\r\n",
        "  print(f'subgroup{i+1} specificity in Ada boost \\n train -> {mean(train_specificity)}  test -> {mean(test_specificity)}')\r\n",
        "  print(f'subgroup{i+1} mcc in Ada boost \\n train -> {mean(train_mcc)}  test -> {mean(test_mcc)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8UQMCkJKCzx"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFUkBWZAKKXo"
      },
      "source": [
        "rf = RandomForestClassifier()\r\n",
        "\r\n",
        "for i,X in enumerate(Xs):\r\n",
        "  train_acc = []\r\n",
        "  test_acc = []\r\n",
        "  train_sensitivity = []\r\n",
        "  test_sensitivity = []\r\n",
        "  train_specificity = []\r\n",
        "  test_specificity = []\r\n",
        "  train_mcc = []\r\n",
        "  test_mcc = []\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index]\r\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\r\n",
        "    rf.fit(X_train, y_train)\r\n",
        "    y_pred = rf.predict(X_train)\r\n",
        "    train_acc.append(accuracy_score(y_train, y_pred))\r\n",
        "    cf = confusion_matrix(y_train, y_pred)\r\n",
        "    train_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    train_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    train_mcc.append(matthews_corrcoef(y_train, y_pred))\r\n",
        "\r\n",
        "    rf.fit(X_train, y_train)\r\n",
        "    y_pred = rf.predict(X_test)\r\n",
        "    test_acc.append(accuracy_score(y_test, y_pred))\r\n",
        "    cf = confusion_matrix(y_test, y_pred)\r\n",
        "    test_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    test_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    test_mcc.append(matthews_corrcoef(y_test, y_pred))\r\n",
        "  print(f'subgroup{i+1} accuracy in Random forest \\n train -> {mean(train_acc)}  test -> {mean(test_acc)}')\r\n",
        "  print(f'subgroup{i+1} sensitivity in Random forest \\n train -> {mean(train_sensitivity)}  test -> {mean(test_sensitivity)}')\r\n",
        "  print(f'subgroup{i+1} specificity in Random forest \\n train -> {mean(train_specificity)}  test -> {mean(test_specificity)}')\r\n",
        "  print(f'subgroup{i+1} mcc in Random forest \\n train -> {mean(train_mcc)}  test -> {mean(test_mcc)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWx1MPJBKjUB"
      },
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYAiik6OKxOL"
      },
      "source": [
        "svc = SVC()\r\n",
        "\r\n",
        "for i,X in enumerate(Xs):\r\n",
        "  train_acc = []\r\n",
        "  test_acc = []\r\n",
        "  train_sensitivity = []\r\n",
        "  test_sensitivity = []\r\n",
        "  train_specificity = []\r\n",
        "  test_specificity = []\r\n",
        "  train_mcc = []\r\n",
        "  test_mcc = []\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index]\r\n",
        "    y_train, y_test = Ytrain[train_index], Ytrain[test_index]\r\n",
        "    svc.fit(X_train, y_train)\r\n",
        "    y_pred = svc.predict(X_train)\r\n",
        "    train_acc.append(accuracy_score(y_train, y_pred))\r\n",
        "    cf = confusion_matrix(y_train, y_pred)\r\n",
        "    train_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    train_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    train_mcc.append(matthews_corrcoef(y_train, y_pred))\r\n",
        "\r\n",
        "    svc.fit(X_train, y_train)\r\n",
        "    y_pred = svc.predict(X_test)\r\n",
        "    test_acc.append(accuracy_score(y_test, y_pred))\r\n",
        "    cf = confusion_matrix(y_test, y_pred)\r\n",
        "    test_sensitivity.append(cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "    test_specificity.append(cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "    test_mcc.append(matthews_corrcoef(y_test, y_pred))\r\n",
        "  print(f'subgroup{i+1} accuracy in svc \\n train -> {mean(train_acc)}  test -> {mean(test_acc)}')\r\n",
        "  print(f'subgroup{i+1} sensitivity in svc \\n train -> {mean(train_sensitivity)}  test -> {mean(test_sensitivity)}')\r\n",
        "  print(f'subgroup{i+1} specificity in svc \\n train -> {mean(train_specificity)}  test -> {mean(test_specificity)}')\r\n",
        "  print(f'subgroup{i+1} mcc in svc \\n train -> {mean(train_mcc)}  test -> {mean(test_mcc)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eW0Tf4RK8RJ"
      },
      "source": [
        "Independent Test(Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDLPOIBWK8-N"
      },
      "source": [
        "lg = LogisticRegression(max_iter=500)\r\n",
        "\r\n",
        "acc = []\r\n",
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "mcc = []\r\n",
        "lg.fit(Xtrain, Ytrain)\r\n",
        "y_pred = lg.predict(Xtest)\r\n",
        "acc = accuracy_score(Ytest, y_pred)\r\n",
        "cf = confusion_matrix(Ytest, y_pred)\r\n",
        "sensitivity = (cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "specificity = (cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "mcc = matthews_corrcoef(Ytest, y_pred)\r\n",
        "\r\n",
        "print(f'acc -> {acc} \\n sensitivity -> {sensitivity} \\n specificity -> {specificity} \\n mcc -> {mcc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Orwuhc8LKbd"
      },
      "source": [
        "Independent Test(XG Boost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DenrdA6zLLAt"
      },
      "source": [
        "xgbst = XGBClassifier()\r\n",
        "\r\n",
        "acc = []\r\n",
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "mcc = []\r\n",
        "xgbst.fit(Xtrain, Ytrain)\r\n",
        "y_pred = xgbst.predict(Xtest)\r\n",
        "acc = accuracy_score(Ytest, y_pred)\r\n",
        "cf = confusion_matrix(Ytest, y_pred)\r\n",
        "sensitivity = (cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "specificity = (cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "mcc = matthews_corrcoef(Ytest, y_pred)\r\n",
        "\r\n",
        "print(f'acc -> {acc} \\n sensitivity -> {sensitivity} \\n specificity -> {specificity} \\n mcc -> {mcc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUeRN1CzLa5n"
      },
      "source": [
        "Independent Test(Ada Boost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxQb99l8Lbfu"
      },
      "source": [
        "ab = AdaBoostClassifier()\r\n",
        "\r\n",
        "acc = []\r\n",
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "mcc = []\r\n",
        "ab.fit(Xtrain, Ytrain)\r\n",
        "y_pred = ab.predict(Xtest)\r\n",
        "acc = accuracy_score(Ytest, y_pred)\r\n",
        "cf = confusion_matrix(Ytest, y_pred)\r\n",
        "sensitivity = (cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "specificity = (cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "mcc = matthews_corrcoef(Ytest, y_pred)\r\n",
        "\r\n",
        "print(f'acc -> {acc} \\n sensitivity -> {sensitivity} \\n specificity -> {specificity} \\n mcc -> {mcc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrbK4CL9Lljw"
      },
      "source": [
        "Independent Test(Rand. forest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjEd0x43LmHt"
      },
      "source": [
        "rf = RandomForestClassifier()\r\n",
        "\r\n",
        "acc = []\r\n",
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "mcc = []\r\n",
        "rf.fit(Xtrain, Ytrain)\r\n",
        "y_pred = rf.predict(Xtest)\r\n",
        "acc = accuracy_score(Ytest, y_pred)\r\n",
        "cf = confusion_matrix(Ytest, y_pred)\r\n",
        "sensitivity = (cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "specificity = (cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "mcc = matthews_corrcoef(Ytest, y_pred)\r\n",
        "\r\n",
        "print(f'acc -> {acc} \\n sensitivity -> {sensitivity} \\n specificity -> {specificity} \\n mcc -> {mcc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMXhoQojLxAF"
      },
      "source": [
        "Independent Test(SVC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oJvDyd8Lxhf"
      },
      "source": [
        "svc = SVC()\r\n",
        "\r\n",
        "acc = []\r\n",
        "sensitivity = []\r\n",
        "specificity = []\r\n",
        "mcc = []\r\n",
        "svc.fit(Xtrain, Ytrain)\r\n",
        "y_pred = svc.predict(Xtest)\r\n",
        "acc = accuracy_score(Ytest, y_pred)\r\n",
        "cf = confusion_matrix(Ytest, y_pred)\r\n",
        "sensitivity = (cf[0,0]/(cf[0,0] + cf[0,1]))\r\n",
        "specificity = (cf[1,1]/(cf[1,0] + cf[1,1]))\r\n",
        "mcc = matthews_corrcoef(Ytest, y_pred)\r\n",
        "\r\n",
        "print(f'acc -> {acc} \\n sensitivity -> {sensitivity} \\n specificity -> {specificity} \\n mcc -> {mcc}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}